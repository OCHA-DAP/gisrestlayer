GENERATING EVENTS FOR THE EVENT BUS
===================================

DETECTING CHANGES ENDPOINT
--------------------------
The endpoint :code:`/api/create-change-events` is used for detecting changes between 2 dataset versions. It needs to be called via a POST request with a JSON body.
The JSON object should have exactly 3 fields:

* *username* - it identifies the user that triggered the change
* *old_dataset_dict*
* *new_dataset_dict*

Implementation notes
++++++++++++++++++++

The entire logic for detecting changes happens in `detect_changes.py <tasks/detect_changes.py>`_ . The worker runs the :code:`detect_changes()` function from here.

All generated **event categories** have corresponding Python classes which inherit from the :code:`Event` base class. Each category can have several **event types**.

The events are generated by the *\*Detector* classes: DatasetChangeDetector, ResourceChangeDetector, SpreadsheetChangeDetector

The list below shows the event categories, their type and the Detector class that generates them:

*  :code:`DatasetEvent`

   *  *dataset-created* - generated by DatasetChangeDetector
   *  *dataset-metadata-changed* - generated by DatasetChangeDetector
   *  [TODO]: please note that for now there is no *dataset-deleted* event

*  :code:`ResourceEvent`

   *  *resource-created* - generated by DatasetChangeDetector
   *  *resource-deleted* - generated by DatasetChangeDetector
   *  *resource-metadata-changed* - generated by ResourceChangeDetector
   *  *resource-data-changed* - generated by ResourceChangeDetector

*  :code:`FileStructureEvent`

   *  *spreadsheet-sheet-created* - generated by ResourceChangeDetector
   *  *spreadsheet-sheet-deleted* - generated by ResourceChangeDetector
   *  *spreadsheet-sheet-changed* - generated by SpreadsheetChangeDetector


EVENT BUS
---------

We're using Redis Streams as our event bus. Once the events have been generated they're pushed to redis streams.

The interaction with redis streams is abstracted away by using the `HDX REDIS LIB <https://github.com/OCHA-DAP/hdx-redis-lib>`_ library

[TODO]: For now the worker connects to the "redis queue" redis instance which is not ideal. It also uses DB 7. This needs to become configurable via ENV VARS.

Implementation notes
+++++++++++++++++++++++++++++++++++++
For pushing events, we have the file `stream_redis.py <helpers/stream_redis.py>`_ . It basically uses the *HDX REDIS LIB* to do all the communication with redis.

For testing purposes, there's also example code for listening for events in the event bus in the file `read_redis_stream.py <read_redis_stream.py>`_ .
This is a standalone program that can be run via:

.. code-block:: bash

   python read_redis_stream.py --host redis --db 7 --n8n-webhook https://[SOME_N8N_WEBSERVER]/webhook/[WEBHOOK_ID]

As can be seen in the example above, you can specify redis connection parameters when running the *read_redis_stream.py* script.
One can also tell it to send the events to some N8N webhook to trigger a workflow.



